{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn this script, we prepare the census tracts\\nand split the shapefile in smaller parts\\nfor better performance when running the main\\napplication.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "In this script, we prepare the census tracts\n",
    "and split the shapefile in smaller parts\n",
    "for better performance when running the main\n",
    "application.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geofeather import to_geofeather, from_geofeather\n",
    "from shapely.geometry import Polygon, MultiPolygon, LineString\n",
    "from shapely.ops import split\n",
    "from sys import getsizeof\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import glob, multiprocessing, os, shutil\n",
    "gpd.options.use_pygeos = True\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path_to_tracts, path_to_shp):\n",
    "    \n",
    "    dtype = { \n",
    "        \n",
    "        \"CD_GEOCODI\": str,\n",
    "        \"CD_GEOCODM\": str,\n",
    "        \"CD_MUNICIP\": str,\n",
    "        \"Cod_setor\": str\n",
    "        \n",
    "    }\n",
    "    \n",
    "    tracts = pd.read_csv(path_to_tracts, dtype=dtype)\n",
    "    \n",
    "    shp = gpd.read_file(path_to_shp, dtype=dtype)\n",
    "    \n",
    "    return tracts, shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tracts_and_shape(tracts, shp):\n",
    "    \n",
    "    return shp.merge(tracts, left_on='CD_GEOCODI', right_on='Cod_setor', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_bbox(rectangle, nrows, ncols): \n",
    "    '''\n",
    "    Divides a rectangular bounding box in\n",
    "    rows and columns\n",
    "\n",
    "    Reference: https://stackoverflow.com/questions/58283684/how-to-divide-a-rectangle-in-specific-number-of-rows-and-columns\n",
    "    '''\n",
    "\n",
    "    minx, miny, maxx, maxy = rectangle.bounds\n",
    "\n",
    "    dx = (maxx - minx) / nrows  # width of a small part\n",
    "\n",
    "    dy = (maxy - miny) / ncols  # height of a small part\n",
    "\n",
    "    horizontal_splitters = [LineString([(minx, miny + i*dy), (maxx, miny + i*dy)]) for i in range(ncols)]\n",
    "\n",
    "    vertical_splitters = [LineString([(minx + i*dx, miny), (minx + i*dx, maxy)]) for i in range(nrows)]\n",
    "\n",
    "    splitters = horizontal_splitters + vertical_splitters\n",
    "\n",
    "    for splitter in splitters:\n",
    "        rectangle = MultiPolygon(split(rectangle, splitter))\n",
    "\n",
    "    return [ split_rectangle for split_rectangle in rectangle ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neighbors(row, gdf):\n",
    "    '''\n",
    "    Finds all the polygons in the GeoDataFrame\n",
    "    that are neighbors to the current row\n",
    "    '''\n",
    "\n",
    "    neighbors = gdf [ ~gdf.geometry.disjoint(row.geometry)].id_no.astype(str).tolist() \n",
    "    \n",
    "    neighbors = \"|\".join(neighbors)\n",
    "\n",
    "    return pd.Series({\"neighbors\": neighbors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intersections(tracts, spatial_index, area):\n",
    "    '''\n",
    "    Finds all the polygons that intersect a given area\n",
    "    '''\n",
    "    \n",
    "    # Uses Geopandas/PyGeos rtree to pre-filter the tracts\n",
    "    nearby_index = list(spatial_index.intersection(area.bounds))\n",
    "    \n",
    "    nearby_tracts = tracts.iloc[nearby_index]\n",
    "\n",
    "    # Selects the tracts that do intersect with the area\n",
    "    matches = nearby_tracts [ nearby_tracts.geometry.intersects(area)]\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_population_in_area(matches, area):\n",
    "    '''\n",
    "    Calculates how many people live in the intersecting polygons.\n",
    "    Also returns an array with the intersecting shapes.\n",
    "    '''\n",
    "\n",
    "    def process_intersection(population, tract, polygon):\n",
    "\n",
    "        intersection = tract.intersection(polygon)\n",
    "\n",
    "        intersection_percentage = intersection.area / tract.area \n",
    "\n",
    "        population_in_intersection = population * intersection_percentage\n",
    "\n",
    "        return intersection, intersection_percentage, population_in_intersection\n",
    "    \n",
    "    \n",
    "\n",
    "    intersection, intersection_percentage, population_in_intersection = process_intersection(matches.populacao_residente.values,\n",
    "                                     matches.geometry.values,\n",
    "                                     area)\n",
    "\n",
    "    matches['geometry'] = intersection\n",
    "    \n",
    "    matches['INTERSECT'] = intersection_percentage.round(2)\n",
    "\n",
    "    matches['POP_INTER'] = population_in_intersection.round()\n",
    "\n",
    "    return matches.reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():    \n",
    "    \n",
    "    print(\"Reading data\")\n",
    "    \n",
    "    df, gdf = read_data(\"../data/censo_dados_resumidos.csv\",\"../data/setores_censitarios_shp_reduzido/\")\n",
    "    \n",
    "    gdf = merge_tracts_and_shape(df, gdf)    \n",
    "    \n",
    "    gdf.geometry = gdf.geometry.buffer(0)\n",
    "    \n",
    "    print(\"Creating spatial index\")\n",
    "    \n",
    "    sindex = gdf.sindex\n",
    "    \n",
    "    print(\"Creating bounding boxes\")\n",
    "    \n",
    "    brazil_bbox = Polygon([\n",
    "        [-74.3143068749,-34.2970741167],\n",
    "        [-34.4119631249,-34.2970741167],\n",
    "        [-34.4119631249,5.648611595],\n",
    "        [-74.3143068749,5.648611595],\n",
    "        [-74.3143068749,-34.2970741167]\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    bboxes = divide_bbox(brazil_bbox, 150, 150)\n",
    "    \n",
    "    bboxes = gpd.GeoDataFrame(geometry=bboxes).reset_index().rename(columns={'index':'id_no'})\n",
    "    \n",
    "    bboxescrs = gdf.crs\n",
    "    \n",
    "    print(\"Finding neighbors\")\n",
    "    \n",
    "    bboxes['neighbors'] = bboxes.apply(find_neighbors, args=[bboxes], axis=1)\n",
    "\n",
    "    bboxes['neighbor_count'] = bboxes.neighbors.str.len()\n",
    "    \n",
    "    \n",
    "    # TO DO: isolate this in a function to increase efficiency\n",
    "    # TO DO: implement this using multithreading and dataframe chunks\n",
    "    # See https://stackoverflow.com/questions/40357434/pandas-df-iterrows-parallelization\n",
    "    \n",
    "    print(\"Preparing geofeathers\")\n",
    "    \n",
    "    meaningful_bboxes = [ ]\n",
    "    \n",
    "    bboxes[\"fpath\"] = None\n",
    "    \n",
    "    bboxes[\"total_population\"] = None\n",
    "    \n",
    "    # directory =  \"../data/setores_censitarios_divididos/\"\n",
    "    \n",
    "    directory =  \"../data/setores_censitarios_divididos_feather/\"\n",
    "        \n",
    "    # Clears the directory of any file \n",
    "    \n",
    "    for f in glob.glob(directory + \"*\"):\n",
    "        \n",
    "        os.remove(f)\n",
    "    \n",
    "    for index, row in bboxes.iterrows():\n",
    "        \n",
    "        print(f\"Processing bounding box {index + 1} of {bboxes.shape[0]}\".ljust(100), end='\\r')\n",
    "        \n",
    "        # Takes a polygon\n",
    "        \n",
    "        bbox = row.geometry\n",
    "        \n",
    "        # Finds the intersecting tracts and do the relevant computations\n",
    "        \n",
    "        matches = find_intersections(gdf, sindex, bbox)\n",
    "        \n",
    "        matches = compute_population_in_area(matches, bbox)\n",
    "        \n",
    "        # Adds relevant information to the bboxes dataframe\n",
    "        \n",
    "        total_population = matches.POP_INTER.sum()        \n",
    "        \n",
    "        #fpath = f\"../data/setores_censitarios_divididos/bbox-{index}.shp\"\n",
    "        \n",
    "        fname =  f'bbox-{index}.feather'\n",
    "        \n",
    "        fpath = directory + fname\n",
    "        \n",
    "        bboxes.loc[index, \"fpath\"] = fpath\n",
    "        \n",
    "        bboxes.loc[index, \"total_population\"] = round(total_population)\n",
    "        \n",
    "        # If relevant, saves\n",
    "        if matches.shape[0] != 0:\n",
    "            \n",
    "            meaningful_bboxes.append(index)\n",
    "            \n",
    "            #matches.to_file(fpath)\n",
    "            \n",
    "            to_geofeather(matches, fpath)\n",
    "    \n",
    "    \n",
    "    # Remove from the data table all the bounding boxes that contain no tracts\n",
    "    bboxes = bboxes.loc[meaningful_bboxes].reset_index(drop=False)\n",
    "    \n",
    "    #bboxes.to_csv(\"../data/index_bboxes.csv\", index=False)\n",
    "    \n",
    "    to_geofeather(bboxes, \"../data/index_bboxes.feather\")\n",
    "    \n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "Creating spatial index\n",
      "Creating bounding boxes\n",
      "Finding neighbors\n",
      "Preparing geofeathers\n",
      "Processing bounding box 22500 of 22500                                                              \r"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 229 ms, sys: 12.1 ms, total: 241 ms\n",
      "Wall time: 237 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = from_geofeather(\"../data/setores_censitarios_divididos_feather/bbox-6104.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = from_geofeather(\"../data/index_bboxes.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.total_population.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y = gpd.read_file(\"../data/setores_censitarios_divididos/bbox-2669.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, gdf = read_data(\"../data/censo_dados_resumidos.csv\",\"../data/setores_censitarios_shp_reduzido/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gdf.loc[0, 'geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
